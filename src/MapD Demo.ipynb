{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End to End GPU Processing With PyMapD, PyGDF, and H2O4GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pymapd import connect\n",
    "import pygdf\n",
    "import pyarrow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h2o4gpu\n",
    "from h2o4gpu import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = connect(user=\"mapd\", password=os.environ[\"mapd_password\"],\n",
    "                  host=\"ec2-12-345-678-910.compute-1.amazonaws.com\",dbname=\"mapd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['taxi_weather_tracts_factual',\n",
       " 'nyc_trees_2015_683k',\n",
       " 'flights_2008_7M',\n",
       " 'trips']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.get_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_query = \"SELECT total_amount, passenger_count, precipitation, trip_distance \\\n",
    "                FROM trips \\\n",
    "                LIMIT 1000000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymapd.cursor.Cursor at 0x7fb47eef3978>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.execute(trips_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = pygdf.DataFrame.from_pandas(pd.DataFrame(c.fetchall())\\\n",
    "                                    .rename(columns={0:\"total_amount\", 1:\"passenger_count\",\n",
    "                                                     2:\"precipitation\", 3:\"trip_distance\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_amount</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>trip_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.80</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_amount  passenger_count  precipitation  trip_distance\n",
       "0          7.00                1              0           0.87\n",
       "1          4.80                2              0           0.30\n",
       "2         18.12                1              0           3.04\n",
       "3          8.00                1              0           1.10\n",
       "4         27.00                2              0           6.20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips.to_pandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into training, validation, and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitpoint: 0.8 of 1000000 is 800000\n",
      "gdfs[\"train\"] has 800001 rows\n",
      "gdfs[\"valid\"] has 200000 rows\n"
     ]
    }
   ],
   "source": [
    "# enforce float64 data type on ALL columns\n",
    "for k in trips.columns:\n",
    "    trips[k] = trips[k].astype(np.float64)\n",
    "\n",
    "# set the fractions for training and validation\n",
    "fractions = {\n",
    "    \"train\": 0.8,\n",
    "    \"valid\": 0.2\n",
    "}\n",
    "\n",
    "# validation splitpoint\n",
    "splitpoint = int(len(trips) * fractions[\"train\"])\n",
    "print('splitpoint: {} of {} is {}'.format(fractions[\"train\"], len(trips), splitpoint))\n",
    "\n",
    "# break the gdf up into training, validation, and test sets\n",
    "gdfs = {\n",
    "    \"train\": trips.loc[:splitpoint],\n",
    "    \"valid\": trips.loc[splitpoint:]\n",
    "}\n",
    "print('gdfs[\"train\"] has {} rows'.format(len(gdfs[\"train\"])))\n",
    "print('gdfs[\"valid\"] has {} rows'.format(len(gdfs[\"valid\"])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert GDFs to GPU Matrices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrices[\"train\"][\"x\"] shape: (800001, 3)\n",
      "matrices[\"train\"][\"y\"] shape: (800001, 1)\n",
      "matrices[\"valid\"][\"x\"] shape: (200000, 3)\n",
      "matrices[\"valid\"][\"y\"] shape: (200000, 1)\n"
     ]
    }
   ],
   "source": [
    "# produce gpu matrices (to input to ml libraries, etc)# produc \n",
    "# this step should not be necessary in the near future\n",
    "# (should be able to use gdf as input)\n",
    "matrices = {\n",
    "    \"train\": {\n",
    "        \"x\": gdfs[\"train\"].as_gpu_matrix(columns=trips.columns[1:]),\n",
    "        \"y\": gdfs[\"train\"].as_gpu_matrix(columns=[trips.columns[0]])\n",
    "    },\n",
    "    \"valid\": {\n",
    "        \"x\": gdfs[\"valid\"].as_gpu_matrix(columns=trips.columns[1:]),\n",
    "        \"y\": gdfs[\"valid\"].as_gpu_matrix(columns=[trips.columns[0]])\n",
    "    }\n",
    "}\n",
    "\n",
    "# check the matrix shapes (sanity check)\n",
    "print('matrices[\"train\"][\"x\"] shape:', matrices[\"train\"][\"x\"].shape)\n",
    "print('matrices[\"train\"][\"y\"] shape:', matrices[\"train\"][\"y\"].shape)\n",
    "print('matrices[\"valid\"][\"x\"] shape:', matrices[\"valid\"][\"x\"].shape)\n",
    "print('matrices[\"valid\"][\"y\"] shape:', matrices[\"valid\"][\"y\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain pointers to the matrices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pointers (so we can keep data on gpu)\n",
    "# this step should not be necessary in the near future\n",
    "# (should be able to use gdf as input)\n",
    "\n",
    "from ctypes import *\n",
    "\n",
    "def get_pointer(matrix):\n",
    "    return c_void_p(matrix.device_ctypes_pointer.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train XGBoost Model With H2O4GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(backend='h2o4gpu', base_score=0.5, booster='gbtree',\n",
       "       colsample_bylevel=1, colsample_bytree=1.0, gamma=0,\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, n_gpus=-1,\n",
       "       n_jobs=1, nthread=None, num_parallel_tree=1, objective='reg:linear',\n",
       "       predictor='gpu_predictor', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1.0, tree_method='gpu_hist')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensure that we use the h2o4gpu backend (not sklearn)\n",
    "xgb = GradientBoostingRegressor(backend = \"h2o4gpu\")\n",
    "\n",
    "# convert input data from gdf to cpu matrices (numpy ndarrays)\n",
    "cpu_matrices = {\n",
    "    \"train\": {\n",
    "        \"x\": gdfs[\"train\"].as_matrix(columns=trips.columns[1:]),\n",
    "        \"y\": gdfs[\"train\"].as_matrix(columns=[trips.columns[0]]).flatten()\n",
    "    },\n",
    "    \"test\": {\n",
    "        \"x\": gdfs[\"valid\"].as_matrix(columns=trips.columns[1:]),\n",
    "        \"y\": gdfs[\"valid\"].as_matrix(columns=[trips.columns[0]]).flatten()\n",
    "    }\n",
    "}\n",
    "\n",
    "# set the base parameters\n",
    "num_rounds = 10\n",
    "xgb_params = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"n_estimators\": 100,\n",
    "    \"subsample\": 1.0,\n",
    "    \"n_gpus\": 1\n",
    "}\n",
    "xgb.set_params(**xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.05 s, sys: 269 ms, total: 1.32 s\n",
      "Wall time: 1.32 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(backend='h2o4gpu', base_score=0.5, booster='gbtree',\n",
       "       colsample_bylevel=1, colsample_bytree=1.0, gamma=0,\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, n_gpus=-1,\n",
       "       n_jobs=1, nthread=None, num_parallel_tree=1, objective='reg:linear',\n",
       "       predictor='gpu_predictor', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1.0, tree_method='gpu_hist')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# fit the model\n",
    "xgb.fit(X = cpu_matrices[\"train\"][\"x\"], y = cpu_matrices[\"train\"][\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.730211   9.34366   12.54071    9.06083   14.327643  11.88019\n",
      "  5.5042825 11.862956   6.4842734 11.178525   7.1239367  7.1239367\n",
      "  9.06083    5.5042825  8.707001  14.658997  15.037864  13.892837\n",
      "  8.78333    9.988817 ]\n"
     ]
    }
   ],
   "source": [
    "# predict based upon test values\n",
    "xgb_predictions = xgb.model.predict(cpu_matrices[\"test\"][\"x\"])\n",
    "\n",
    "# show the first 20 results\n",
    "print(xgb_predictions[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
